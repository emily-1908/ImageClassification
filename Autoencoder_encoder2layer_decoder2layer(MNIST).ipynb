{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data vectorizing & labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_zero', '1_one', '2_two', '3_three', '4_four', '5_five', '6_six',\n",
       "       '7_seven', '8_eight', '9_nine'], dtype='<U7')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data path\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "TRAIN_DIR = 'D:/MNIST/trainingSet/'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    "train_folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path 라벨링\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
    "integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integer_encoded:\n",
      " [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "onehot_encoded:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 라벨링 벡터화\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(categories='auto', sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print('integer_encoded:\\n', integer_encoded)\n",
    "print('onehot_encoded:\\n', onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 불러와서 흑백으로 벡터화 및 라벨링\n",
    "import cv2\n",
    "train_input = []\n",
    "train_label = []\n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # cv2.imread: paht경로에 있는 이미지를 흑백으로 불러옴\n",
    "        train_input.append([np.array(img)])\n",
    "        train_label.append([np.array(onehot_encoded[index])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25ad52b4f60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 마지막 이미지 시각화\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input) #train_input은 [[img],[img],...,[img]] 이런 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list형태를 np.array형태(42000,784)로 reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input.shape:  (42000, 784)\n",
      "train_label.shape:  (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_input = np.reshape(train_input, (-1, 784))\n",
    "# 이때 -1은 정확한 개수를 모를때 사용. -1대신 42000 넣어도 상관x\n",
    "train_label = np.reshape(train_label, (-1, 10))\n",
    "train_input = np.array(train_input).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.float32)\n",
    "\n",
    "#데이터 섞기\n",
    "tmp = [[x,y] for x, y in zip(train_input, train_label)]\n",
    "np.random.shuffle(tmp)\n",
    "train_input = np.array([n[0] for n in tmp])\n",
    "train_label = np.array([n[1] for n in tmp])\n",
    "\n",
    "np.save(\"train_data.npy\", train_input)\n",
    "np.save(\"train_label.npy\", train_label)\n",
    "print('train_input.shape: ', train_input.shape)\n",
    "print('train_label.shape: ', train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data vectorizing & labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = 'D:/MNIST/testSet/'\n",
    "test_folder_list = array(os.listdir(TEST_DIR))\n",
    " \n",
    "test_input = []\n",
    "test_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(test_folder_list)\n",
    " \n",
    "onehot_encoder = OneHotEncoder(categories='auto', sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(test_folder_list)):\n",
    "    path = os.path.join(TEST_DIR, test_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_input.append([np.array(img)])\n",
    "        test_label.append([np.array(onehot_encoded[index])])\n",
    " \n",
    "test_input = np.reshape(test_input, (-1, 784))\n",
    "test_label = np.reshape(test_label, (-1, 10))\n",
    "test_input = np.array(test_input).astype(np.float32)\n",
    "test_label = np.array(test_label).astype(np.float32)\n",
    "\n",
    "#데이터 섞기\n",
    "tmp = [[x,y] for x, y in zip(test_input, test_label)]\n",
    "np.random.shuffle(tmp)\n",
    "test_input = np.array([n[0] for n in tmp])\n",
    "test_label = np.array([n[1] for n in tmp])\n",
    "\n",
    "np.save(\"test_input.npy\",test_input)\n",
    "np.save(\"test_label.npy\",test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder와 Softmax 분류기를 이용한 MNIST 분류기 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 학습에 필요한 설정값들을 정의  \n",
    "learning_rate_RMSProp = 0.02\n",
    "learning_rate_GradientDescent = 0.01\n",
    "num_epochs = 100         # 반복횟수\n",
    "batch_size = 256          \n",
    "display_step = 5         # 몇 Step마다 loss를 출력할지 결정\n",
    "input_size = 784\n",
    "hidden1_size = 128       # 첫번째 히든레이어의 노드 개수 \n",
    "hidden2_size = 64        # 두번째 히든레이어의 노드 개수 \n",
    "\n",
    "# 입력값과 출력값을 받기 위한 플레이스홀더를 정의\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_size])   \n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder 구조를 정의\n",
    "def build_autoencoder(x):\n",
    "    # 인코딩(Encoding) - 784 -> 128 -> 64\n",
    "    Wh_1 = tf.Variable(tf.random_normal([input_size, hidden1_size]))   \n",
    "    bh_1 = tf.Variable(tf.random_normal([hidden1_size]))\n",
    "    H1_output = tf.nn.sigmoid(tf.matmul(x, Wh_1) +bh_1)\n",
    "    Wh_2 = tf.Variable(tf.random_normal([hidden1_size, hidden2_size]))\n",
    "    bh_2 = tf.Variable(tf.random_normal([hidden2_size]))\n",
    "    H2_output = tf.nn.sigmoid(tf.matmul(H1_output, Wh_2) +bh_2)\n",
    "    # 디코딩(Decoding) 64 -> 128 -> 784\n",
    "    Wh_3 = tf.Variable(tf.random_normal([hidden2_size, hidden1_size]))\n",
    "    bh_3 = tf.Variable(tf.random_normal([hidden1_size]))\n",
    "    H3_output = tf.nn.sigmoid(tf.matmul(H2_output, Wh_3) +bh_3)\n",
    "    Wo = tf.Variable(tf.random_normal([hidden1_size, input_size]))\n",
    "    bo = tf.Variable(tf.random_normal([input_size]))\n",
    "    X_reconstructed = tf.nn.sigmoid(tf.matmul(H3_output,Wo) + bo)\n",
    "  \n",
    "    return X_reconstructed, H2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax 분류기를 정의\n",
    "def build_softmax_classifier(x):\n",
    "    # 원본 MNIST 이미지(784) 대신 오토인코더의 압축된 특징(64)을 입력값으로 받음\n",
    "    W_softmax = tf.Variable(tf.zeros([hidden2_size, 10])) \n",
    "    b_softmax = tf.Variable(tf.zeros([10]))\n",
    "    y_pred = tf.nn.softmax(tf.matmul(x, W_softmax) + b_softmax) \n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder를 선언\n",
    "# y_pred : Autoencoder의 Reconstruction 결과(784) \n",
    "# extracted_features : 압축된 Features(64)\n",
    "y_pred, extracted_features = build_autoencoder(x) \n",
    "# 타겟데이터는 인풋데이터와 같음\n",
    "y_true = x\n",
    "\n",
    "# Softmax 분류기를 선언 \n",
    "# 입력으로 Autoencoder의 압축된 특징을 삽입\n",
    "y_pred_softmax = build_softmax_classifier(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1013 15:32:50.478839 32120 deprecation.py:323] From C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1013 15:32:50.534689 32120 deprecation.py:506] From C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# 1. Pre-Training(사전학습) : MNIST 데이터 재구축을 목적으로하는 손실함수와 옵티마이저를 정의\n",
    "pretraining_loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2)) # MSE 손실 함수\n",
    "pretraining_train_step = tf.train.RMSPropOptimizer(learning_rate_RMSProp).minimize(pretraining_loss)\n",
    "\n",
    "# 2. Fine-Tuning(전이학습) :  MNIST 데이터 분류를 목적으로하는 손실함수와 옵티마이저를 정의\n",
    "finetuning_loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred_softmax), reduction_indices=[1])) # cross-entropy loss 함수\n",
    "finetuning_train_step = tf.train.GradientDescentOptimizer(learning_rate_GradientDescent).minimize(finetuning_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 5, Pre-Training 손실 함수(pretraining_loss): 0.368925\n",
      "반복(Epoch): 10, Pre-Training 손실 함수(pretraining_loss): 0.084791\n",
      "반복(Epoch): 15, Pre-Training 손실 함수(pretraining_loss): 0.068866\n",
      "반복(Epoch): 20, Pre-Training 손실 함수(pretraining_loss): 0.055227\n",
      "반복(Epoch): 25, Pre-Training 손실 함수(pretraining_loss): 0.049867\n",
      "반복(Epoch): 30, Pre-Training 손실 함수(pretraining_loss): 0.044509\n",
      "반복(Epoch): 35, Pre-Training 손실 함수(pretraining_loss): 0.040615\n",
      "반복(Epoch): 40, Pre-Training 손실 함수(pretraining_loss): 0.037530\n",
      "반복(Epoch): 45, Pre-Training 손실 함수(pretraining_loss): 0.036124\n",
      "반복(Epoch): 50, Pre-Training 손실 함수(pretraining_loss): 0.034098\n",
      "반복(Epoch): 55, Pre-Training 손실 함수(pretraining_loss): 0.033208\n",
      "반복(Epoch): 60, Pre-Training 손실 함수(pretraining_loss): 0.031424\n",
      "반복(Epoch): 65, Pre-Training 손실 함수(pretraining_loss): 0.027504\n",
      "반복(Epoch): 70, Pre-Training 손실 함수(pretraining_loss): 0.026810\n",
      "반복(Epoch): 75, Pre-Training 손실 함수(pretraining_loss): 0.026182\n",
      "반복(Epoch): 80, Pre-Training 손실 함수(pretraining_loss): 0.025049\n",
      "반복(Epoch): 85, Pre-Training 손실 함수(pretraining_loss): 0.024564\n",
      "반복(Epoch): 90, Pre-Training 손실 함수(pretraining_loss): 0.024060\n",
      "반복(Epoch): 95, Pre-Training 손실 함수(pretraining_loss): 0.023631\n",
      "반복(Epoch): 100, Pre-Training 손실 함수(pretraining_loss): 0.023292\n",
      "Step 1 : MNIST 데이터 재구축을 위한 오토인코더 최적화 완료(Pre-Training)\n"
     ]
    }
   ],
   "source": [
    "# 세션을 열고 변수들에 초기값을 할당\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 전체 배치 개수를 불러옴\n",
    "total_batch = int(len(train_input)/batch_size) # total_batch = int(42000/256) = 164\n",
    "\n",
    "# Step 1: MNIST 데이터 재구축을 위한 오토인코더 최적화(Pre-Training)를 수행\n",
    "for epoch in range(num_epochs): #num_epochs = 30\n",
    "    average_loss = 0\n",
    "    # 모든 배치들에 대해서 최적화를 수행\n",
    "    for i in range(total_batch):\n",
    "        start = ((i+1) * batch_size) - batch_size\n",
    "        # 데이터를 분할하기 위해 start라는 변수를 선언\n",
    "        # i는 0에서 164까지 변함\n",
    "        # i = 0일 때 start에 저장되는 값은 (0+1)*256)-256이므로 0이 저장\n",
    "        end = ((i+1) * batch_size)\n",
    "        # 데이터를 분할하기 위해 end라는 변수를 선언\n",
    "        # i = 0일 때 emd에 저장되는 값은 (0+1)*256)이므로 256이 저장\n",
    "        batch_xs = train_input[start:end] / 255\n",
    "        # batch_xs : train 데이터의 input을 저장하는 변수\n",
    "        # train_input[start:end]는 train_input[0:256]과 같음\n",
    "        # 즉, train_inpuf에서 0~256에 위치하는 데이터를 불러서 batch_xs에 저장\n",
    "        feed_dict = {x: batch_xs}\n",
    "        # feed dictionary를 선언\n",
    "        # x는 input data에 대한 placeholder\n",
    "        _, pretraining_loss_print = sess.run([pretraining_train_step, pretraining_loss], feed_dict=feed_dict)\n",
    "        # 옵티마이저를 실행해서 파라마터들을 업데이트\n",
    "        average_loss += pretraining_loss_print / total_batch\n",
    "        # 평균 손실을 측정\n",
    "    # 지정된 epoch마다 학습결과를 출력\n",
    "    if epoch % display_step == 0: # display_step = 5\n",
    "        print(\"반복(Epoch): %d, Pre-Training 손실 함수(pretraining_loss): %f\" % ((epoch+display_step), average_loss))\n",
    "print(\"Step 1 : MNIST 데이터 재구축을 위한 오토인코더 최적화 완료(Pre-Training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25ada8af4e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 마지막 이미지 시각화\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(np.reshape(batch_xs[0], (28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 5, Fine-tuning 손실 함수(finetuning_loss): 2.203775\n",
      "반복(Epoch): 10, Fine-tuning 손실 함수(finetuning_loss): 1.489438\n",
      "반복(Epoch): 15, Fine-tuning 손실 함수(finetuning_loss): 1.116228\n",
      "반복(Epoch): 20, Fine-tuning 손실 함수(finetuning_loss): 0.912886\n",
      "반복(Epoch): 25, Fine-tuning 손실 함수(finetuning_loss): 0.791080\n",
      "반복(Epoch): 30, Fine-tuning 손실 함수(finetuning_loss): 0.711124\n",
      "반복(Epoch): 35, Fine-tuning 손실 함수(finetuning_loss): 0.654678\n",
      "반복(Epoch): 40, Fine-tuning 손실 함수(finetuning_loss): 0.612553\n",
      "반복(Epoch): 45, Fine-tuning 손실 함수(finetuning_loss): 0.579751\n",
      "반복(Epoch): 50, Fine-tuning 손실 함수(finetuning_loss): 0.553353\n",
      "반복(Epoch): 55, Fine-tuning 손실 함수(finetuning_loss): 0.531547\n",
      "반복(Epoch): 60, Fine-tuning 손실 함수(finetuning_loss): 0.513152\n",
      "반복(Epoch): 65, Fine-tuning 손실 함수(finetuning_loss): 0.497363\n",
      "반복(Epoch): 70, Fine-tuning 손실 함수(finetuning_loss): 0.483616\n",
      "반복(Epoch): 75, Fine-tuning 손실 함수(finetuning_loss): 0.471498\n",
      "반복(Epoch): 80, Fine-tuning 손실 함수(finetuning_loss): 0.460706\n",
      "반복(Epoch): 85, Fine-tuning 손실 함수(finetuning_loss): 0.451006\n",
      "반복(Epoch): 90, Fine-tuning 손실 함수(finetuning_loss): 0.442220\n",
      "반복(Epoch): 95, Fine-tuning 손실 함수(finetuning_loss): 0.434206\n",
      "반복(Epoch): 100, Fine-tuning 손실 함수(finetuning_loss): 0.426851\n",
      "반복(Epoch): 105, Fine-tuning 손실 함수(finetuning_loss): 0.420063\n",
      "반복(Epoch): 110, Fine-tuning 손실 함수(finetuning_loss): 0.413769\n",
      "반복(Epoch): 115, Fine-tuning 손실 함수(finetuning_loss): 0.407905\n",
      "반복(Epoch): 120, Fine-tuning 손실 함수(finetuning_loss): 0.402422\n",
      "반복(Epoch): 125, Fine-tuning 손실 함수(finetuning_loss): 0.397275\n",
      "반복(Epoch): 130, Fine-tuning 손실 함수(finetuning_loss): 0.392427\n",
      "반복(Epoch): 135, Fine-tuning 손실 함수(finetuning_loss): 0.387848\n",
      "반복(Epoch): 140, Fine-tuning 손실 함수(finetuning_loss): 0.383510\n",
      "반복(Epoch): 145, Fine-tuning 손실 함수(finetuning_loss): 0.379391\n",
      "반복(Epoch): 150, Fine-tuning 손실 함수(finetuning_loss): 0.375469\n",
      "반복(Epoch): 155, Fine-tuning 손실 함수(finetuning_loss): 0.371727\n",
      "반복(Epoch): 160, Fine-tuning 손실 함수(finetuning_loss): 0.368150\n",
      "반복(Epoch): 165, Fine-tuning 손실 함수(finetuning_loss): 0.364723\n",
      "반복(Epoch): 170, Fine-tuning 손실 함수(finetuning_loss): 0.361435\n",
      "반복(Epoch): 175, Fine-tuning 손실 함수(finetuning_loss): 0.358275\n",
      "반복(Epoch): 180, Fine-tuning 손실 함수(finetuning_loss): 0.355234\n",
      "반복(Epoch): 185, Fine-tuning 손실 함수(finetuning_loss): 0.352301\n",
      "반복(Epoch): 190, Fine-tuning 손실 함수(finetuning_loss): 0.349470\n",
      "반복(Epoch): 195, Fine-tuning 손실 함수(finetuning_loss): 0.346734\n",
      "반복(Epoch): 200, Fine-tuning 손실 함수(finetuning_loss): 0.344087\n",
      "Step 2 : MNIST 데이터 분류를 위한 오토인코더+Softmax 분류기 최적화 완료(Fine-Tuning)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: MNIST 데이터 분류를 위한 오토인코더+Softmax 분류기 최적화(Fine-tuning)를 수행\n",
    "# 이때 오토인코더의 파라미터들은 MNIST 데이터 재구축이 아니라 숫자 분류를 목적으로 다시 한번 최적화됨\n",
    "for epoch in range(num_epochs + 100): #num_epochs = 100\n",
    "    average_loss = 0\n",
    "    # 모든 배치들에 대해서 최적화를 수행\n",
    "    for i in range(total_batch): # total_batch = 164\n",
    "        start = ((i+1) * batch_size) - batch_size\n",
    "        # 데이터를 분할하기 위해 start라는 변수를 선언\n",
    "        # i는 0에서 164까지 변함\n",
    "        # i = 0일 때 start에 저장되는 값은 (0+1)*256)-256이므로 0이 저장\n",
    "        end = ((i+1) * batch_size)\n",
    "        # 데이터를 분할하기 위해 end라는 변수를 선언\n",
    "        # i = 0일 때 emd에 저장되는 값은 (0+1)*256)이므로 256이 저장\n",
    "        batch_xs = train_input[start:end] / 255\n",
    "        # batch_xs : train 데이터의 input을 저장하는 변수\n",
    "        # train_input[start:end]는 train_input[0:256]과 같음\n",
    "        # 즉, train_inpuf에서 0~256에 위치하는 데이터를 불러서 batch_xs에 저장\n",
    "        batch_ys = train_label[start:end]\n",
    "        # batch_ys = train 데이터의 label을 저장하는 변수\n",
    "        # train_label[start:end]는 train_label[0:256]과 같음\n",
    "        # train_label에서 0~100에 위치하는 데이터를 불러서 batch_ys에 저장\n",
    "        feed_dict = {x: batch_xs, y: batch_ys}\n",
    "        # feed dictionary를 선언\n",
    "        # x는 input data에 대한 placeholder이며, \n",
    "        # y는 output data 즉, label를 담는 placeholder임\n",
    "        # x에 batch_xs를 담고, y에 batch_ys를 담음 \n",
    "        # 옵티마이저를 실행해서 파라마터들을 업데이트\n",
    "        _, finetuning_loss_print = sess.run([finetuning_train_step, finetuning_loss], feed_dict=feed_dict)\n",
    "        # 평균 손실을 측정\n",
    "        average_loss += finetuning_loss_print / total_batch\n",
    "    # 지정된 epoch마다 학습결과를 출력\n",
    "    if epoch % display_step == 0: # display_step = 5\n",
    "        print(\"반복(Epoch): %d, Fine-tuning 손실 함수(finetuning_loss): %f\" % ((epoch+display_step), average_loss))\n",
    "print(\"Step 2 : MNIST 데이터 분류를 위한 오토인코더+Softmax 분류기 최적화 완료(Fine-Tuning)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도(오토인코더+Softmax 분류기): 0.870000\n"
     ]
    }
   ],
   "source": [
    "# 오토인코더+Softmax 분류기 모델의 정확도를 출력\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_pred_softmax,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"정확도(오토인코더+Softmax 분류기): %f\" % sess.run(accuracy, feed_dict={x: test_input, y: test_label})) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내가 그린 데이터로 연습해보기(myMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.png',\n",
       " '2.png',\n",
       " '3.png',\n",
       " '4.png',\n",
       " '5.png',\n",
       " '6.png',\n",
       " '7.png',\n",
       " '7_2.png',\n",
       " '8.png',\n",
       " '9.png']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data path\n",
    "import os\n",
    "path = 'D:/myMNIST/'\n",
    "myimg_list = os.listdir(path)\n",
    "myimg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "mytrain_input = []\n",
    "for img in myimg_list:\n",
    "    img_path = os.path.join(path, img)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # cv2.imread: paht경로에 있는 이미지를 흑백으로 불러옴\n",
    "    mytrain_input.append([np.array(img)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25ada91da20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 마지막 이미지 시각화\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "mytrain_input = np.reshape(mytrain_input, (-1, 784))\n",
    "mytrain_input = mytrain_input.astype(np.float32)\n",
    "print(mytrain_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 2, 5, 4, 5, 4, 2, 3, 8, 3], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytrain_input = mytrain_input / 255\n",
    "correct_prediction = tf.argmax(y_pred_softmax, 1)\n",
    "sess.run(correct_prediction, feed_dict={x: mytrain_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAABRCAYAAAAZ1Ej0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAKY0lEQVR4nO3dT6gdZxnH8d9j7MVFBVtFDWm0rQQxK1NLddGF4KZkU1wIXdldNhYq6CLophuXdiUIKe1CKZRCA81OpFTRTalK2houqUkXNuZSKTVYXViSPi7u3Pbk5tyZOe/8e9/n/X7gcO8995wz72/mfee888575pi7CwAAAJv7xNIFAAAAKBUdKQAAgER0pAAAABLRkQIAAEhERwoAACARHSkAAIBEgzpSZvaQmV00s0tmdnqsQuWEjOWLnk8iYxTRM0bPJ5GxSu6edJN0SNJlSfdK2pL0mqTjqa+X442M5d+i5yPj8mUjI/nIGCvjprchI1IPSLrk7m+5+weSnpP08IDXyxEZyxc9n0TGKKJnjJ5PImOVPjnguUckvb3y9xVJ39z/IDM7JelU8+c3BixvMWa2d/n376vCjMHyvS/pV2v+HyljlfW0+X/ojMHy0RZ3kTFz7m5t/x/SkVr3wrd834y7n5F0RrppxZesuozB8r2rCrehRMZC0RbLR8YYGQ80pCN1RdLRlb/vknR1WHGyR8bybSl2PinTbdjMr/iIWetBXpcsM44sekbaYgw1ZGw1ZI7Uq5KOmdk9ZrYl6RFJ58YpVrbIWL47FTufFH8bSmSMgLYYQw0ZWyWPSLn7dTN7TNJvtDuL/xl3vzBayfL0PBmL995S+UYekWmz+Dbcn/WgxwxYB4tnnEH0jIu1xRkttg3XtcGJ9jnR62kn67PDG21hhZ8n7ZpwJsXPWHo+SX929/vbHjBVxrk6UjnU0777ldR1kEPGqdEWy8+4ZD2dqyNFWxw2R2oRM/ayF7eaNWpGlGVdndz0YIy6jNzUsq/dy1lixpz3M3xFDAAAQKLiRqQia+txl3wkcZCImfbMecp8KX0yRty2e2oZxShVahsscb/UljV15DgXJZS7mI5UCStziL75Smzk++3PGukNKWo9rb3TtGrdusi1XabUx9wypIjaDld1ZYy6HdtyLbXdObUHAACQqJgRqaj69rjXjeKUdsQR/Sixa1uWmJ+RqJvV8GGXPqeJStK3zKW0z2jbp69Ns805SsyIFAAAQCJGpDLS1nOOOGGw9Ex7Io9S9BkdrUGp2ziljH0+9DLk9TGeqOt/033M0vukIjpSS68kpCv1DShV5Gw1qq3+SptN5i1xikFtSnr/LLW9cWoPAAAgUREjUquinA7aU0JvO0WpRxabiFIH0V+0Ooy6RKu/ueyDGZECAABIVMSIVLRedI36Tlou+aO9Y5av1IuURpmMnMuRbi5YH3kaa1J2zu20hLrHiBQAAECiIkakUJ4pLuOf69dw7En5BFMJR1tduj4un+v2SlHiEf0UassbXS7tNPVyK0tf+JiOFGaTetou187Gug8+bFLWGr4rS8q/AzyGKKc018m1/bWJtP73S71Se6nXhCthW3JqDwAAIFGIEakaj3gjKX27jXFJjtLXgVTuEW8fXdun9Jyllx83Y3t+bI7+ASNSAAAAiYodkYp2YU5ps4msJY5glFjmTaTMXYiwTjbNHSFzl1KyRv3gBz5W2zZaom9QbEcqmk2+KBRY0iY7ZjMLUX+7Og6lHtjtz1PDNxJEVlr9i4JTewAAAIkYkVpYnyPAriuARz1i5OgKSzlohClqnWQkqmxsv2UxIgUAAJCIEakMjfX9SVJ5RyWRsqB8qXOfSqmrUUfYahf9ch256RyRMrOjZvaymW2b2QUze7y5/04z+62Z/a35ecf0xV1WDRkrcGjpAkythnpaQ8YK0BYDqCFjlz6n9q5L+pG7f03StyT9wMyOSzot6SV3Pybppebvybn7Tbe2/x30uAFmybiOmd1y68PddfXq1YlLN0zXdtokbw9fHOuFxjBy/dwzWT2doE2lmrUtrmt/bbdSzZwhq7Y4kUXeM9reCyeYT7XY+2IuLGHI+kVJv2hu33b3HTM7LOl37v7Vjucm733H2nEPrDBvTpkxB+7euoLm2oYT7sj/5+6f6lj2LNtwwg8MTFZPN90JTzgJlrY4QVucuROYTVuUJvu+xFnqaer7Y0kZNzXm9uxqixvNkTKzuyWdkPSKpC+4+06zkB0z+/wBzzkl6dQmy8lYDRlvESzf2jofLGMN9bSGjLcIlo+2GEMNGVv1HpEys9sl/V7Sz9z9rJldc/fPrPz/X+7eeq609CNESdeiZ5zqKLirns14JHzD3VsPIAKMSE1aTxc++t1DWxxxGy50OjKbtihNtk7C11NlmnHOEalelz8ws9skvSDpWXc/29z9TnNKT83PfyaXshw1ZIzu+tIFmEEN9bSGjNHRFmOoIWOrPp/aM0lPS9p29ydX/nVO0qPN749KenH84mWnhoyTyGhy7rU5F9bXyBO4J62nmUyopi2WL8u2OLIa6mmWGed8j+k8tWdmD0r6g6Q3JH3Y3P0T7c6Tel7SlyT9XdL33P29jtcqfQjzs9EzTnk6IRPn3f1E2wMCnE4IX09VQUbaYoiM4eupKsg4eLK5u/9R0kEv8p2UQpWqq7KgCDeWLsDUaqinNWSsAG0xgBoyduErYgAAABLRkQIAAEjEd+0BC8pg0jYAYABGpAAAABLRkQIAAEhERwoAACARHSkAAIBEc082f1fSf5ufufucbi7nl3s+7z+SLo5fnEmkZCx5G0rxM/atpzVkpC3mg7Z4sBoyhm6Lvb+0eCxm9id3v3/WhSZILWcp+aT4GYeUk4z5iF5PpfgZqafTPXdO0euplFZWTu0BAAAkoiMFAACQaImO1JkFlpkitZyl5JPiZxxSTjLmI3o9leJnpJ5O99w5Ra+nUkJZZ58jBQAAEAWn9gAAABLRkQIAAEg0W0fKzB4ys4tmdsnMTs+13C5mdtTMXjazbTO7YGaPN/c/YWb/MLPzze1kj9ci40LGyphrPil+RuopGfe9Tuh8zXPIuJAxM8rdJ79JOiTpsqR7JW1Jek3S8TmW3aNshyXd1/z+aUlvSjou6QlJPyZjPRlzzldDRuopGWvJR8Y4Gd19thGpByRdcve33P0DSc9JenimZbdy9x13/0vz+/uStiUdSXgpMi5opIzZ5pPiZ6SebiR6xuj5JDIuasSMs3Wkjkh6e+XvK0os8JTM7G5JJyS90tz1mJm9bmbPmNkdHU8nYyYGZCwinxQ/I/W0+ozR80lkzMbAjLN1pGzNfVldd8HMbpf0gqQfuvu/Jf1S0lckfV3SjqSfd73EmvvIOLOBGbPPJ8XPSD0lo+Lnk8iYhREyztaRuiLp6Mrfd0m6OtOyO5nZbdpdkc+6+1lJcvd33P2Gu38o6SntDlG2IePCRsiYdT4pfkbqKRkb0fNJZFzcSBln60i9KumYmd1jZluSHpF0bqZltzIzk/S0pG13f3Ll/sMrD/uupL92vBQZFzRSxmzzSfEzUk8/Qsb4+SQyLmrEjPN8as93Z8Wf1O6s+MuSfjrXcnuU60HtDjW+Lul8czsp6deS3mjuPyfpMBnjZ8w1Xw0ZqadkrCkfGeNk5CtiAAAAEnFlcwAAgER0pAAAABLRkQIAAEhERwoAACARHSkAAIBEdKQAAAAS0ZECAABI9H84Z2lBZTLtFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 원본 MNIST 데이터와 Reconstruction 결과를 비교\n",
    "f, a = plt.subplots(1, 10, figsize=(10, 1))\n",
    "for i in range(len(mytrain_input)):\n",
    "    a[i].imshow(np.reshape(mytrain_input[i], (28, 28)), cmap='gray')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 0.3\n",
    "기존 ANN(3layer)보다 성능이 안좋음..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
