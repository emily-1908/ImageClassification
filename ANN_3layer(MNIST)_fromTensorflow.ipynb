{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 이미지 데이터에 라벨링, 벡터화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_zero', '1_one', '2_two', '3_three', '4_four', '5_five', '6_six',\n",
       "       '7_seven', '8_eight', '9_nine'], dtype='<U7')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data path\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "TRAIN_DIR = 'D:/MNIST/trainingSet/'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    "train_folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path 라벨링\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
    "integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integer_encoded:\n",
      " [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "onehot_encoded:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 라벨링 벡터화\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print('integer_encoded:\\n', integer_encoded)\n",
    "print('onehot_encoded:\\n', onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 불러와서 흑백으로 벡터화 및 라벨링\n",
    "import cv2\n",
    "train_input = []\n",
    "train_label = []\n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # cv2.imread: paht경로에 있는 이미지를 흑백으로 불러옴\n",
    "        train_input.append([np.array(img)])\n",
    "        train_label.append([np.array(onehot_encoded[index])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19d4125c828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARfElEQVR4nO3dbYxWZXoH8P8FM6O8jMhLB6nQ7nYlpsZEtgKpiErV3QhfkBBWSAQaSWc/YLNEYmrsB4ifjHbZ8KFZM1sJUCgbkl0LwbVAYBMlMRtGwwqUtFJFmGUCi4A8vA4MVz/MYTPic65rfM5znnPg+v8SMjPPNefMzcP8eV6uc9+3qCqI6PY3qOgBEFFjMOxEQTDsREEw7ERBMOxEQTQ18oeJCN/6z4GI1HwsuzG18e7zIu9XVa06uExhF5FnAKwGMBjAv6nq61nOF5X3izNokP0EbPDgwak175fu2rVrZj3rL631d8vz3PU4v6WpyY7O1atXc/vZtar5abyIDAbwrwBmAngAwAIReaBeAyOi+srymn0qgMOq+pmq9gD4JYDZ9RkWEdVblrDfC+BYv6+7ktu+RkTaRaRTRDoz/CwiyijLa/ZqL5i+8SJJVTsAdAB8g46oSFke2bsATOj39XgAx7MNh4jykiXsewFMFJHvikgLgPkAttZnWERUbzU/jVfVayLyIoDt6Gu9rVHVg3Ub2W1kyJAhZv3SpUtmvbe3N1Pd4rX1sravrPNfv37dPDZrS9Li3Wfe37uMrTWPNLL5H/U1e9aw58kLjBdIj3UNwK0c9jJLu6iGl8sSBcGwEwXBsBMFwbATBcGwEwXBsBMFwdZbA3gtoqy97ix99qy8qZ7eFNo8Wa07b9xZpwYXia03ouAYdqIgGHaiIBh2oiAYdqIgGHaiIBq6lHRU3uwur56ldZfnuQfCan95587aUrTaZ965syzPXVZ8ZCcKgmEnCoJhJwqCYScKgmEnCoJhJwqCYScKglNcG+COO+4w614vPM9li4tcXdabZurxppkWOfW3SJziShQcw04UBMNOFATDThQEw04UBMNOFATDThQE++wl4PW6rV41kG8f3tuB1uuVVyqVeg7na5qbm826db/ezj36tD57pqsaROQIgAqAXgDXVHVylvMRUX7qsVLN36nqqTqch4hyxNfsREFkDbsC2CEiH4lIe7VvEJF2EekUkc6MP4uIMsj0Bp2I/LmqHheRNgA7Afyjqr5vfD/foKuCb9DVhm/QVZfLRBhVPZ58PAngHQBTs5yPiPJTc9hFZJiItN74HMAPARyo18CIqL6yvBs/FsA7yfraTQD+Q1X/qy6jCsZ7KpznGubeuS9dupTp/KNGjUqtnT59OtO5vZcvLS0tqbWs15eUeavqNDWHXVU/A/BQHcdCRDli640oCIadKAiGnSgIhp0oCIadKAhu2dwA3hVyXgupra3NrD/55JOptUWLFtV8LOC3qL744guzvmzZstTawYMHzWOPHj1q1j1W+yvrEtm3Ij6yEwXBsBMFwbATBcGwEwXBsBMFwbATBcGwEwVxSy0l7fWrLV5f1VsNxlqx5fz58+axo0ePNutz5swx6wsXLjTrjz/+eGrt4sWL5rFbtmwx6/Pnzzfr3u+P9W/22muvmceuWLHCrHtbYV+5ciW15v17W9NjgexTf/PELZuJgmPYiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmhon72pqUnvuuuu1PqZM2fM463eZ09Pj3ms11f1dgCx+sULFiwwj92wYYNZ93R3d5v11atXp9a2bdtmHuvNKfd2hHniiSfM+ssvv5xamzFjhnnsqlWraj53VkOHDjXr3vULRWKfnSg4hp0oCIadKAiGnSgIhp0oCIadKAiGnSiIhq4b39vba/bShw8fbh5vzRtvbW01j61UKmbd68Nv2rQptTZv3jzz2MuXL5v1zz//3Kx7/eQPPvggtXbu3DnzWI+39fDu3bvN+j333JNae/jhh81jp02bZtanT59u1j/88MPUWnNzs3ms10e3rhcBst/veXAf2UVkjYicFJED/W4bJSI7ReTT5OPIfIdJRFkN5Gn8WgDP3HTbKwB2qepEALuSr4moxNywq+r7AE7fdPNsAOuSz9cBeLbO4yKiOqv1NftYVe0GAFXtFpHUzchEpB1Ae40/h4jqJPc36FS1A0AHkH3BSSKqXa2ttxMiMg4Ako8n6zckIspDrWHfCmBx8vliAPZ6xERUOHc+u4hsAjADwBgAJwCsAPCfADYD+AsARwHMU9Wb38T7hkGDBqnV3/TmpFvrhHtrynvrfC9ZssSsv/XWW6k1by68N9/dW7tdpOr05AH9fO/6gZEj7a7pqVOnzLrHGru3d/zatWvNurev/SOPPJJaO3DgQGoNsNecL7u0+ezua3ZVTftNfSrTiIiooXi5LFEQDDtREAw7URAMO1EQDDtREA2d4qqq7pRJi9XGydoq8VpQTU3pd5X3d3rppZfM+rBhw8z62bNnzfqOHTtSa147M2trzds22Zqm+tBDD2X62Z7Nmzen1p577jnz2M7OTrOeZbvoovCRnSgIhp0oCIadKAiGnSgIhp0oCIadKAiGnSiIhm7Z7K1UM3r0aPP4L7/8sq7j6e++++4z6+vXr0+tWVMpAX8raq/H7zlx4kRqbezYseaxXj/Y6yd7fXxrm22Ptxyzt5xzV1dXam3ChAnmsd6U6evXr5v1InHLZqLgGHaiIBh2oiAYdqIgGHaiIBh2oiAYdqIgGtpnb2pqUmtb5q+++so83ur5ev1iaz464M8pt8ycOdOsP/WUvRDv/fffb9Yfe+wxs25df3D33Xebx3rLVB8/ftysjx8/3qxv3bq15nO/++67Zn3OnDlm/YUXXkiteXPp9+/fb9a93ydvmes8sc9OFBzDThQEw04UBMNOFATDThQEw04UBMNOFESp5rMP4PjUWt59T2vrY2/L5rzXGB8xYkRq7fz58+ax3thbW1vNeqVSMetDhw5NrV28eNE81tPW1mbWjx49mlp7+umnzWP37NlT05jKoOY+u4isEZGTInKg320rReQPIrIv+TOrnoMlovobyNP4tQCeqXL7z1R1UvLnN/UdFhHVmxt2VX0fwOkGjIWIcpTlDboXReST5Gl+6iJqItIuIp0iYm+eRUS5qjXsPwfwPQCTAHQD+GnaN6pqh6pOVtXJNf4sIqqDmsKuqidUtVdVrwP4BYCp9R0WEdVbTWEXkXH9vpwD4EDa9xJRObj7s4vIJgAzAIwRkS4AKwDMEJFJABTAEQA/znGMf2JdE5D3/GGvH23xxuZdI+Dt/26tA+Cd25vP7vXRvfXVrV66dX0A4K9vMHfuXLNuuXz5sln31je4cOFCzT+7KG7YVXVBlZvfzmEsRJQjXi5LFATDThQEw04UBMNOFATDThSE+248Zedt7+u1x+68806zbrWRvLZdVlm2LvZaa55p06aZdWtqsbWkOeC31rJO/S0CH9mJgmDYiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmCfvQR6enoyHe/16S3eMtcerx9tXSMwcmTqamYAgO7ubrPu/b2tacnbt283j/W20T5y5IhZLyM+shMFwbATBcGwEwXBsBMFwbATBcGwEwXBsBMFcUtt2XyrsrYtBrJvXWz1m/Oez56n6dOnm/Xdu3ebdWu+/JQpU8xjjx07ZtatLbyB7NdOZFHzls1EdHtg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYLgfPYGuHTpUqbjvW2V8+ylt7S0mHVvPrzVb75y5Yp57LZt28x6c3OzWV+1alVqzZuP7p27yD56rdxHdhGZICK/FZFDInJQRH6S3D5KRHaKyKfJR3slAiIq1ECexl8DsFxV/xrA3wJYKiIPAHgFwC5VnQhgV/I1EZWUG3ZV7VbVj5PPKwAOAbgXwGwA65JvWwfg2bwGSUTZfavX7CLyHQDfB/A7AGNVtRvo+w9BRNpSjmkH0J5tmESU1YDDLiLDAfwKwDJVPee9aXSDqnYA6EjOEXIiDFEZDKj1JiLN6Av6RlX9dXLzCREZl9THATiZzxCJqB7cR3bpewh/G8AhVe3fy9gKYDGA15OPW3IZ4W3Am0bsta+uXr1a8/m97Z6HDBli1r1tlb0WVFtb1Vd3AIA33njDPHbEiBFmff369Wb9zTffTK15U1S9dmaWbbSLMpCn8Y8CWAhgv4jsS257FX0h3ywiSwAcBTAvnyESUT24YVfVPQDSXqA/Vd/hEFFeeLksURAMO1EQDDtREAw7URAMO1EQXEq6BFpbW816pVKp+dxeD9+bZurxpoKuWbMmtfb888+bx7733ntmfdasWWbdMmbMGLN+6tQps17mPjuXkiYKjmEnCoJhJwqCYScKgmEnCoJhJwqCYScKgn32EsizF+7NV/eWuX7wwQfN+sqVK8363LlzU2tnz541jx050l6w2JuTbl0D4PXBvXP39vaa9SKxz04UHMNOFATDThQEw04UBMNOFATDThQEw04UBLdsboBhw4aZ9QsXLmQ6v9WPPnPmTKZzb9iwwaxPnDjRrHd1daXWFi1aVNOYbsi63r6lkdefNAof2YmCYNiJgmDYiYJg2ImCYNiJgmDYiYJg2ImCcOezi8gEAOsB3APgOoAOVV0tIisB/AOAPybf+qqq/sY51+3XvGwAb232LP3k7du3m/UpU6aY9b1795r1pUuXptYOHz5sHuvJ834ZPny4WffWAShyvnvafPaBXFRzDcByVf1YRFoBfCQiO5Paz1T1X+o1SCLKz0D2Z+8G0J18XhGRQwDuzXtgRFRf3+o1u4h8B8D3AfwuuelFEflERNaISNVrNkWkXUQ6RaQz00iJKJMBh11EhgP4FYBlqnoOwM8BfA/AJPQ98v+02nGq2qGqk1V1ch3GS0Q1GlDYRaQZfUHfqKq/BgBVPaGqvap6HcAvAEzNb5hElJUbdhERAG8DOKSqq/rdPq7ft80BcKD+wyOiehnIu/GPAlgIYL+I7EtuexXAAhGZBEABHAHw41xGeBvo+/8yndf+zNJCamlpMete+2r58uVmfePGjWa9p6cntebdL0OHDq353J6mJvtX37vPy7yUdJqBvBu/B0C1fxWzp05E5cIr6IiCYNiJgmDYiYJg2ImCYNiJgmDYiYLgls0l4PW6vSWTrX51pVIxj21tbTXr3vEeaxltr5edpY/uuZW3ZPZwy2ai4Bh2oiAYdqIgGHaiIBh2oiAYdqIgGHaiIBrdZ/8jgC/63TQGwKmGDeDbKevYyjougGOrVT3H9peq+mfVCg0N+zd+uEhnWdemK+vYyjougGOrVaPGxqfxREEw7ERBFB32joJ/vqWsYyvruACOrVYNGVuhr9mJqHGKfmQnogZh2ImCKCTsIvKMiPyPiBwWkVeKGEMaETkiIvtFZF/R+9Mle+idFJED/W4bJSI7ReTT5GPVPfYKGttKEflDct/tE5FZBY1tgoj8VkQOichBEflJcnuh950xrobcbw1/zS4igwH8L4AfAOgCsBfAAlX974YOJIWIHAEwWVULvwBDRB4HcB7AelV9MLntDQCnVfX15D/Kkar6TyUZ20oA54vexjvZrWhc/23GATwL4O9R4H1njOtHaMD9VsQj+1QAh1X1M1XtAfBLALMLGEfpqer7AE7fdPNsAOuSz9eh75el4VLGVgqq2q2qHyefVwDc2Ga80PvOGFdDFBH2ewEc6/d1F8q137sC2CEiH4lIe9GDqWKsqnYDfb88ANoKHs/N3G28G+mmbcZLc9/Vsv15VkWEvdr6WGXq/z2qqn8DYCaApcnTVRqYAW3j3ShVthkvhVq3P8+qiLB3AZjQ7+vxAI4XMI6qVPV48vEkgHdQvq2oT9zYQTf5eLLg8fxJmbbxrrbNOEpw3xW5/XkRYd8LYKKIfFdEWgDMB7C1gHF8g4gMS944gYgMA/BDlG8r6q0AFiefLwawpcCxfE1ZtvFO22YcBd93hW9/rqoN/wNgFvrekf8/AP9cxBhSxvVXAH6f/DlY9NgAbELf07qr6HtGtATAaAC7AHyafBxVorH9O4D9AD5BX7DGFTS26eh7afgJgH3Jn1lF33fGuBpyv/FyWaIgeAUdURAMO1EQDDtREAw7URAMO1EQDDtREAw7URD/D237K6E1fsfrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 마지막 이미지 시각화\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input) #train_input은 [[img],[img],...,[img]] 이런 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list형태를 np.array형태(42000,784)로 reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input.shape:  (42000, 784)\n",
      "train_label.shape:  (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_input = np.reshape(train_input, (-1, 784))\n",
    "# 이때 -1은 정확한 개수를 모를때 사용. -1대신 42000 넣어도 상관x\n",
    "train_label = np.reshape(train_label, (-1, 10))\n",
    "train_input = np.array(train_input).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.float32)\n",
    "\n",
    "#데이터 섞기\n",
    "tmp = [[x,y] for x, y in zip(train_input, train_label)]\n",
    "np.random.shuffle(tmp)\n",
    "train_input = np.array([n[0] for n in tmp])\n",
    "train_label = np.array([n[1] for n in tmp])\n",
    "\n",
    "np.save(\"train_data.npy\", train_input)\n",
    "np.save(\"train_label.npy\", train_label)\n",
    "print('train_input.shape: ', train_input.shape)\n",
    "print('train_label.shape: ', train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 이미지 데이터(200개) 숫자 변환 전체코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "TEST_DIR = 'D:/MNIST/testSet/'\n",
    "test_folder_list = array(os.listdir(TEST_DIR))\n",
    " \n",
    "test_input = []\n",
    "test_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(test_folder_list)\n",
    " \n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(test_folder_list)):\n",
    "    path = os.path.join(TEST_DIR, test_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_input.append([np.array(img)])\n",
    "        test_label.append([np.array(onehot_encoded[index])])\n",
    " \n",
    "test_input = np.reshape(test_input, (-1, 784))\n",
    "test_label = np.reshape(test_label, (-1, 10))\n",
    "test_input = np.array(test_input).astype(np.float32)\n",
    "test_label = np.array(test_label).astype(np.float32)\n",
    "\n",
    "#데이터 섞기\n",
    "tmp = [[x,y] for x, y in zip(test_input, test_label)]\n",
    "np.random.shuffle(tmp)\n",
    "test_input = np.array([n[0] for n in tmp])\n",
    "test_label = np.array([n[1] for n in tmp])\n",
    "\n",
    "np.save(\"test_input.npy\",test_input)\n",
    "np.save(\"test_label.npy\",test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ANN을 이용한 MNIST 숫자 분류기 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 학습을 위한 설정값들을 정의\n",
    "learning_rate = 0.01\n",
    "num_epochs = 30     # 학습횟수\n",
    "batch_size = 256    # 배치개수\n",
    "display_step = 1    # 손실함수 출력 주기\n",
    "hidden1_size = 256\n",
    "hidden2_size = 256\n",
    "\n",
    "# 입력값과 출력값을 받기 위한 플레이스홀더를 정의\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN 모델을 정의\n",
    "def build_ANN(x):\n",
    "    W1 = tf.Variable(tf.random_normal(shape=[784, hidden1_size]))\n",
    "    b1 = tf.Variable(tf.random_normal(shape=[hidden1_size]))\n",
    "    H1_output = tf.nn.relu(tf.matmul(x,W1) + b1) # shape (42000,256)\n",
    "    W2 = tf.Variable(tf.random_normal(shape=[hidden1_size, hidden2_size]))\n",
    "    b2 = tf.Variable(tf.random_normal(shape=[hidden2_size]))\n",
    "    H2_output = tf.nn.relu(tf.matmul(H1_output,W2) + b2) # shape (42000,256)\n",
    "    W_output = tf.Variable(tf.random_normal(shape=[hidden2_size, 10]))\n",
    "    b_output = tf.Variable(tf.random_normal(shape=[10]))\n",
    "    logits = tf.matmul(H2_output,W_output) + b_output # shape (42000,10)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN 모델을 선언\n",
    "predicted_value = build_ANN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수와 옵티마이저를 정의\n",
    "# tf.nn.softmax_cross_entropy_with_logits 함수를 이용하여 \n",
    "# 활성함수를 적용하지 않은 output layer의 결과값(logits)에 softmax 함수를 적용\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=predicted_value, labels=y))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 1, 손실 함수(Loss): 23498.151762\n",
      "반복(Epoch): 2, 손실 함수(Loss): 3760.659963\n",
      "반복(Epoch): 3, 손실 함수(Loss): 1878.512662\n",
      "반복(Epoch): 4, 손실 함수(Loss): 1227.919278\n",
      "반복(Epoch): 5, 손실 함수(Loss): 772.338254\n",
      "반복(Epoch): 6, 손실 함수(Loss): 486.392584\n",
      "반복(Epoch): 7, 손실 함수(Loss): 489.420643\n",
      "반복(Epoch): 8, 손실 함수(Loss): 344.089695\n",
      "반복(Epoch): 9, 손실 함수(Loss): 286.061593\n",
      "반복(Epoch): 10, 손실 함수(Loss): 313.062903\n",
      "반복(Epoch): 11, 손실 함수(Loss): 301.218188\n",
      "반복(Epoch): 12, 손실 함수(Loss): 292.806078\n",
      "반복(Epoch): 13, 손실 함수(Loss): 284.278972\n",
      "반복(Epoch): 14, 손실 함수(Loss): 252.630723\n",
      "반복(Epoch): 15, 손실 함수(Loss): 287.388537\n",
      "반복(Epoch): 16, 손실 함수(Loss): 239.432984\n",
      "반복(Epoch): 17, 손실 함수(Loss): 268.742984\n",
      "반복(Epoch): 18, 손실 함수(Loss): 258.925054\n",
      "반복(Epoch): 19, 손실 함수(Loss): 267.084681\n",
      "반복(Epoch): 20, 손실 함수(Loss): 302.148739\n",
      "반복(Epoch): 21, 손실 함수(Loss): 232.690176\n",
      "반복(Epoch): 22, 손실 함수(Loss): 210.625086\n",
      "반복(Epoch): 23, 손실 함수(Loss): 272.683904\n",
      "반복(Epoch): 24, 손실 함수(Loss): 263.124161\n",
      "반복(Epoch): 25, 손실 함수(Loss): 238.224241\n",
      "반복(Epoch): 26, 손실 함수(Loss): 232.064056\n",
      "반복(Epoch): 27, 손실 함수(Loss): 278.457614\n",
      "반복(Epoch): 28, 손실 함수(Loss): 272.988511\n",
      "반복(Epoch): 29, 손실 함수(Loss): 228.360157\n",
      "반복(Epoch): 30, 손실 함수(Loss): 213.845210\n"
     ]
    }
   ],
   "source": [
    "# 세션을 열고 변수들에 초기값을 할당\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 지정된 횟수만큼 최적화를 수행\n",
    "for epoch in range(num_epochs): #num_epochs = 30\n",
    "    average_loss = 0\n",
    "    # 전체 배치를 불러옵니다.\n",
    "    total_batch = int(len(train_input)/batch_size)\n",
    "    # total_batch = int(42000/256) = 164\n",
    "    # 모든 배치들에 대해서 최적화를 수행합니다.\n",
    "    for i in range(total_batch):\n",
    "        start = ((i+1) * batch_size) - batch_size\n",
    "        # 데이터를 분할하기 위해 start라는 변수를 선언\n",
    "        # i는 0에서 164까지 변함\n",
    "        # i = 0일 때 start에 저장되는 값은 (0+1)*256)-256이므로 0이 저장\n",
    "        end = ((i+1) * batch_size)\n",
    "        # 데이터를 분할하기 위해 end라는 변수를 선언\n",
    "        # i = 0일 때 emd에 저장되는 값은 (0+1)*256)이므로 256이 저장\n",
    "        batch_xs = train_input[start:end]\n",
    "        # batch_xs : train 데이터의 input을 저장하는 변수\n",
    "        # train_input[start:end]는 train_input[0:256]과 같음\n",
    "        # 즉, train_inpuf에서 0~256에 위치하는 데이터를 불러서 batch_xs에 저장\n",
    "        batch_ys = train_label[start:end]\n",
    "        # batch_ys = train 데이터의 label을 저장하는 변수\n",
    "        # train_label[start:end]는 train_label[0:256]과 같음\n",
    "        # train_label에서 0~100에 위치하는 데이터를 불러서 batch_ys에 저장\n",
    "        feed_dict = {x: batch_xs, y: batch_ys}\n",
    "        # feed dictionary를 선언\n",
    "        # x는 input data에 대한 placeholder이며, \n",
    "        # y는 output data 즉, label를 담는 placeholder임\n",
    "        # x에 batch_xs를 담고, y에 batch_ys를 담음 \n",
    "        # 옵티마이저를 실행해서 파라마터들을 업데이트\n",
    "        _, current_loss = sess.run([train_step, loss], feed_dict=feed_dict)\n",
    "        # 평균 손실을 측정\n",
    "        average_loss += current_loss / total_batch\n",
    "    # 지정된 epoch마다 학습결과를 출력\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"반복(Epoch): %d, 손실 함수(Loss): %f\" % ((epoch+1), average_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(predicted_value, 1), tf.argmax(y, 1))\n",
    "# 전체 test 데이터 중 실제로 맞춘 개수가 몇개인지 측정한 다음 correct_prediction에 저장\n",
    "# tf.argmax : 원소 중에서 가장 큰 값의 인덱스를 반환. \n",
    "# 즉, predicted_value에서는 가중치 업데이트 후 가장 큰 값을 갖는 인덱스를 \n",
    "# y에서는 0과1 중 1인 것을 찾아서 라벨을 매기기 위함\n",
    "# tf.equal : 예측 값과 정답이 같으면 True 아니면 False값이 반환\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "# tf.cast : correct_prediction을 float형으로 변환. True = 1, False = 0\n",
    "# 변환한 값의 평균을 구하여 accuracy에 저장. 200개 중 몇 개 맞췄는지\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={x: test_input, y: test_label}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내가 그린 데이터로 연습해보기(myMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.png',\n",
       " '2.png',\n",
       " '3.png',\n",
       " '4.png',\n",
       " '5.png',\n",
       " '6.png',\n",
       " '7.png',\n",
       " '7_2.png',\n",
       " '8.png',\n",
       " '9.png']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data path\n",
    "import os\n",
    "path = 'D:/myMNIST/'\n",
    "myimg_list = os.listdir(path)\n",
    "myimg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "mytrain_input = []\n",
    "for img in myimg_list:\n",
    "    img_path = os.path.join(path, img)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # cv2.imread: paht경로에 있는 이미지를 흑백으로 불러옴\n",
    "    mytrain_input.append([np.array(img)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19d4572feb8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 마지막 이미지 시각화\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "mytrain_input = np.reshape(mytrain_input, (-1, 784))\n",
    "mytrain_input = mytrain_input.astype(np.float32)\n",
    "print(mytrain_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 2, 5, 4, 5, 6, 7, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_prediction = tf.argmax(predicted_value, 1)\n",
    "sess.run(correct_prediction, feed_dict={x: mytrain_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 원본 MNIST 데이터와 Reconstruction 결과를 비교\n",
    "f, a = plt.subplots(1, 10, figsize=(10, 1))\n",
    "for i in range(len(mytrain_input)):\n",
    "    a[i].imshow(np.reshape(mytrain_input[i], (28, 28)), cmap='gray')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도= 0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
