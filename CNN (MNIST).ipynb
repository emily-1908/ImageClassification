{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 이미지 데이터 숫자 변환 전체코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    " \n",
    "TRAIN_DIR = 'D:/MNIST/trainingSet/'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    " \n",
    "train_input = []\n",
    "train_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        train_input.append([np.array(img)])\n",
    "        train_label.append([np.array(onehot_encoded[index])])\n",
    " \n",
    "train_input = np.reshape(train_input, (-1, 784))\n",
    "train_label = np.reshape(train_label, (-1, 10))\n",
    "train_input = np.array(train_input).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.float32)\n",
    "#tmp = [[x,y] for x, y in zip(train_input, train_label)]\n",
    "#np.random.shuffle(tmp)\n",
    "#train_input = [n[0] for n in tmp]\n",
    "#train_label = [n[1] for n in tmp]\n",
    "np.save(\"train_data.npy\", train_input)\n",
    "np.save(\"train_label.npy\", train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 이미지 파일 path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_zero', '1_one', '2_two', '3_three', '4_four', '5_five', '6_six',\n",
       "       '7_seven', '8_eight', '9_nine'], dtype='<U7')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "TRAIN_DIR = 'D:/MNIST/trainingSet/'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    "train_folder_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
    "integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integer_encoded:\n",
      " [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "onehot_encoded:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print('integer_encoded:\\n', integer_encoded)\n",
    "print('onehot_encoded:\\n', onehot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지를 불러와서 흑백으로 벡터화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "train_input = []\n",
    "train_label = []\n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # cv2.imread: paht경로에 있는 이미지를 흑백으로 불러옴\n",
    "        train_input.append([np.array(img)])\n",
    "        train_label.append([np.array(onehot_encoded[index])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2286cdec128>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 마지막 이미지 시각화\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list형태를 np.array형태(42000,784)로 reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input) #train_input은 [[array],[array],...,[array]] 이런 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input.shape:  (42000, 784)\n",
      "train_label.shape:  (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_input = np.reshape(train_input, (-1, 784))\n",
    "# 이때 -1은 정확한 개수를 모를때 사용. -1대신 42000 넣어도 상관x\n",
    "train_label = np.reshape(train_label, (-1, 10))\n",
    "train_input = np.array(train_input).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.float32)\n",
    "np.save(\"train_data.npy\", train_input)\n",
    "np.save(\"train_label.npy\", train_label)\n",
    "print('train_input.shape: ', train_input.shape)\n",
    "print('train_label.shape: ', train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 이미지 데이터 숫자 변환 전체코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "TEST_DIR = 'D:/MNIST/testSet/'\n",
    "test_folder_list = array(os.listdir(TEST_DIR))\n",
    " \n",
    "test_input = []\n",
    "test_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(test_folder_list)\n",
    " \n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(test_folder_list)):\n",
    "    path = os.path.join(TEST_DIR, test_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_input.append([np.array(img)])\n",
    "        test_label.append([np.array(onehot_encoded[index])])\n",
    " \n",
    "test_input = np.reshape(test_input, (-1, 784))\n",
    "test_label = np.reshape(test_label, (-1, 10))\n",
    "test_input = np.array(test_input).astype(np.float32)\n",
    "test_label = np.array(test_label).astype(np.float32)\n",
    "np.save(\"test_input.npy\",test_input)\n",
    "np.save(\"test_label.npy\",test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input.shape:  (200, 784)\n",
      "test_label.shape:  (200, 10)\n"
     ]
    }
   ],
   "source": [
    "print('test_input.shape: ', test_input.shape)\n",
    "print('test_label.shape: ', test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델 설계 전체코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    " \n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    " \n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    " \n",
    "# define cost/loss &amp;amp;amp; optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### placeholder: 변수를 담을 그릇 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# placeholder: 재료를 담는 그릇 또는 쟁반\n",
    "# 데이터 타입을 float32로 지정. \n",
    "# [None, 784] : 784의 shape을 갖는 데이터를 0~무한대까지 불러올 수 있음\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   \n",
    "# img 28x28x1 (black/white) \n",
    "# 이때 -1은 batch size. 배치 사이즈는 가변할 수 있으므로 보통 -1로 지정함.\n",
    "# 마지막 1은 channel 수를 의미.\n",
    "# grayscale로 이미지를 불러올 경우 1, RGB로 불러올 경우 3\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "# output data를 불러올 변수를 선언\n",
    "# label의 shape이 [-1,10]dlamfh [None, 10]을 기입 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution layer, max-pooling layer 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "# 초기 가중치 설정\n",
    "# 3*3필터를 사용. 1은 input데이터의 channel, 32는 필터를 32개 쓰겠다는 말\n",
    "# stddev=0.01 : 생성된 난수의 변동이 0.01이라는 뜻 \n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# Convolution layer를 선언하여 L1에 저장\n",
    "# X_img는 해당 Convolution layer의 input\n",
    "# W1은 앞서 선언한 Convolution layer의 필터. \n",
    "# 즉, X_ing에 W1 필터를 활용하여 Convolution layer를 구성하겠다는 뜻 \n",
    "# strides = [1,1,1,1] : stride를 어떻게 움직일 것인가를 설정하는 구문 \n",
    "# 첫번째 1은 모든 batch에 대해 convolution filter를 적용하겠다는 의미\n",
    "# 마지막 1은 모든 채널에 대해 convolution filter를 적용하겠다는 의미\n",
    "# 두번째와 세번째의 1은 필터를 움직일 때 우측으로 한칸 씩, 아래로 한칸 씩 움직인다는 의미 \n",
    "# padding='SAME' : convolution 연산 후 shape이 줄어드는 것을 방지하기 위하여 설정하는 구문\n",
    "# 만약 padding='VALID'로 설정하면 3*3필터가 28*28이미지를 한칸 씩 움직이며 \n",
    "# 연산을 수행하므로 convolution 연산 이후 출력된 결과의 shape은 26*26임.\n",
    "L1 = tf.nn.relu(L1)\n",
    "# Convolution layer의 연산 결과를 RELU activaion function에 적용하겠다는 의미\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# max-pooling layer를 선언하여 L1애 저장\n",
    "# 입력변수는 이전에 선언된 L1\n",
    "# ksize=[1,2,2,1] : kernel사이즈. convolution layer의 filter와 동일한 개념.\n",
    "# 첫번째 1은 모든 batch에 대해 kernel을 적용하겠다는 의미\n",
    "# [2,2]는 2*2크기의 kernel을 사용하겠다는 의미\n",
    "# 마지막 1음 모든 채널에 대해 적용하겠다는 의미\n",
    "# strides=[1,2,2,1] ; kernel 사이즈와 보통 같게 설정 \n",
    "# 2*2 kernel을 사용한다면 오른쪽과 아래로 2칸씩 움직임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer와 max-pooling layer을 한번 더 적용\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(64)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fully-connected layer 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0925 23:23:13.870505 11352 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "# L2의 shape을 [-1, 7*7*64]로 만들어 L2_flat에 저장\n",
    "# 이유는 다음과 같다.\n",
    "# 처음 input data의 shape은 28*28*1이었다. \n",
    "# input data가 convolution layer(L1)을 거쳐 32개의 3*3의 필터와 연산되었으므로 \n",
    "# 이 때의 연산 결과는 28*28*32가 된다.\n",
    "# (padding=\"SAME\"으로 지정하여 data의 크기는 변하지 않는다)\n",
    "# L1은 max-pooling layer(L1)을 거쳐 2*2의 kernel으로 max-pooling 연산을 수행했으므로\n",
    "# 이 때의 연산 결과는 14*14*32가 된다. \n",
    "# 마찬가지로 convolution layer(L2)에서 3*3*64 연산을 수행하면 14*14*64가 되며 \n",
    "# max-pooling(L2)에서 2*2 kernel으로 max-pooling 연산을 수행하면 7*7*64가 된다.\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# fully-connected 연산을 위해 weight를 선언하여 W3에 저장\n",
    "# shpe = [7*7*64, 10] : input data의 shape이 7*7*64이고, \n",
    "#                       output data의 shape이 10(0~9)이므로 \n",
    "#                       W3의 shape을 [7*7*64, 10]으로 설정\n",
    "# weight의 초기값은 성능이 우수한 것으로 알려진 Xavier initializer를 사용\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "# bias를 선언하여 b에 저장\n",
    "# output의 shape이 10이므로 shape을 10으로 설정 \n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    "# L2_flat과 W3 행렬의 곱셈 연산을 수행한 후 bias를 더하여 logits에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost function 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0925 23:29:00.597236 11352 deprecation.py:323] From <ipython-input-24-4c65c8155826>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define cost/loss &amp;amp;amp; optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "# 예측 값(logitis)과 실제 값(Y)의 차이를 나타내는 Cost함수를 선언하여 cost에 저장\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# cost를 최소화하는 optimizer 함수를 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 3.827028446\n",
      "Epoch: 0002 cost = 7.236712608\n",
      "Epoch: 0003 cost = 2.479863492\n",
      "Epoch: 0004 cost = 2.420645193\n",
      "Epoch: 0005 cost = 2.235679866\n",
      "Epoch: 0006 cost = 2.131891612\n",
      "Epoch: 0007 cost = 1.954667708\n",
      "Epoch: 0008 cost = 1.760371308\n",
      "Epoch: 0009 cost = 1.457054643\n",
      "Epoch: 0010 cost = 1.290886561\n",
      "Epoch: 0011 cost = 1.178108456\n",
      "Epoch: 0012 cost = 1.116682474\n",
      "Epoch: 0013 cost = 1.077093674\n",
      "Epoch: 0014 cost = 1.057836399\n",
      "Epoch: 0015 cost = 1.030706614\n",
      "Learning Finished!\n",
      "--- 510.8892331123352 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#시작시간\n",
    "start_time = time.time()\n",
    "\n",
    "training_epochs = 15\n",
    "# 학습 횟수를 설정\n",
    "batch_size = 100\n",
    "# 효과적인 모델 학습을 위해 batch size를 설정\n",
    "# batch size는 학습할 때 몇 개의 데이터를 한번에 학습하는가에 관한 설정\n",
    "# 본 실험에서는 42000개의 데이터를 학습하므로, batch size는 1~42,000까지 설정할 수 있음\n",
    "# 100으로 설정했으므로 한번 학습하는데 100개의 데이터를 사용한다는 의미\n",
    " \n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "# tf.Session클래스를 sess에 저장\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 모든 변수의 weight값을 초기화\n",
    " \n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    # 1 epoch 완료 시 cost의 평균값을 출력하기 위해 avg_cost를 선언한 후 0을 저장\n",
    "    total_batch = int(len(train_input) / batch_size)\n",
    "    # 1 epoch에 몇 회 학습할 것인지 설정 \n",
    "    # train input에 저장된 데이터는 42,000개이므로 len(train_input)은 42,000을\n",
    "    # batch size는 100을 설정했으므로 total_batch는 420이 됨 \n",
    "    for i in range(total_batch):\n",
    "        start = ((i+1) * batch_size) - batch_size\n",
    "        # 데이터를 분할하기 위해 start라는 변수를 선언\n",
    "        # i는 0에서 419까지 변함\n",
    "        # i = 0일 때 start에 저장되는 값은 (0+1)*100)-100이므로 0이 저장\n",
    "        end = ((i+1) * batch_size)\n",
    "        # 데이터를 분할하기 위해 end라는 변수를 선언\n",
    "        # i = 0일 때 emd에 저장되는 값은 (0+1)*100)이므로 100이 저장\n",
    "        batch_xs = train_input[start:end]\n",
    "        # batch_xs : train 데이터의 input을 저장하는 변수\n",
    "        # train_input[start:end]는 train_input[0:100]과 같음\n",
    "        # 즉, train_inpuf에서 0~100에 위치하는 데이터를 불러서 batch_xs에 저장\n",
    "        batch_ys = train_label[start:end]\n",
    "        # batch_ys = train 데이터의 label을 저장하는 변수\n",
    "        # train_label[start:end]는 train_label[0:100]과 같음\n",
    "        # train_label에서 0~100에 위치하는 데이터를 불러서 batch_ys에 저장\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        # feed dictionary를 선언\n",
    "        # X는 input data에 대한 placeholder이며, \n",
    "        # Y는 output data 즉, label를 담는 placeholder임\n",
    "        # X에 batch_xs를 담고, Y에 batch_ys를 담음\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        # Session을 실행\n",
    "        # cost와 optimizer를 실행한 후 c에 cost를 저장 \n",
    "        avg_cost += c / total_batch\n",
    "        # avg_cost += c/total batch : avg_cost에 (c/total_batch)를 더함\n",
    "        # 즉, cost의 평균을 avg_cost에 더하여 저장\n",
    " \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    " \n",
    "print('Learning Finished!')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "# 전체 test 데이터 중 실제로 맞춘 개수가 몇개인지 측정한 다음 \n",
    "# correct_prediction에 저장\n",
    "# tf.equal에서는 예측 값과 정답이 같으면 True 아니면 False값이 반환되는데\n",
    "# 이것을 float형으로 바꾸고 평균을 계산해 정확도를 구함\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# 정확도의 평균을 구하여 accuracy에 저장 \n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: test_input, Y: test_label}))\n",
    "# Accuracy를 출력.\n",
    "# feed_dict={X: test_input, Y: test_label} : X에 test_input을, Y에 test_input을 불러옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제점: cost도 0으로 내려가지 않고, 정확도도 0.45밖에 안된다! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 방법1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치를 random으로 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.031096329\n",
      "Epoch: 0002 cost = 0.000000770\n",
      "Epoch: 0003 cost = 0.000000454\n",
      "Epoch: 0004 cost = 0.000000306\n",
      "Epoch: 0005 cost = 0.000000222\n",
      "Epoch: 0006 cost = 0.000000164\n",
      "Epoch: 0007 cost = 0.000000122\n",
      "Epoch: 0008 cost = 0.000000096\n",
      "Epoch: 0009 cost = 0.000000079\n",
      "Epoch: 0010 cost = 0.000000062\n",
      "Epoch: 0011 cost = 0.000000046\n",
      "Epoch: 0012 cost = 0.000000039\n",
      "Epoch: 0013 cost = 0.000000029\n",
      "Epoch: 0014 cost = 0.000000024\n",
      "Epoch: 0015 cost = 0.000000020\n",
      "Learning Finished!\n",
      "--- 324.1626822948456 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#시작시간\n",
    "start_time = time.time()\n",
    "\n",
    "training_epochs = 15\n",
    "# 학습 횟수를 설정\n",
    "batch_size = 100\n",
    "# 효과적인 모델 학습을 위해 batch size를 설정\n",
    "# batch size는 학습할 때 몇 개의 데이터를 한번에 학습하는가에 관한 설정\n",
    "# 본 실험에서는 42000개의 데이터를 학습하므로, batch size는 1~42,000까지 설정할 수 있음\n",
    "# 100으로 설정했으므로 한번 학습하는데 100개의 데이터를 사용한다는 의미\n",
    "\n",
    "# batch를 random으로 선택\n",
    "train_size = train_input.shape[0]\n",
    "batch_mask = np.random.choice(train_size, batch_size)    \n",
    "    \n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "# tf.Session클래스를 sess에 저장\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 모든 변수의 weight값을 초기화\n",
    " \n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    # 1 epoch 완료 시 cost의 평균값을 출력하기 위해 avg_cost를 선언한 후 0을 저장\n",
    "    total_batch = int(len(train_input) / batch_size)\n",
    "    # 1 epoch에 몇 회 학습할 것인지 설정 \n",
    "    # train input에 저장된 데이터는 42,000개이므로 len(train_input)은 42,000을\n",
    "    # batch size는 100을 설정했으므로 total_batch는 420이 됨 \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = train_input[batch_mask]\n",
    "        # batch_xs : train 데이터의 input을 저장하는 변수\n",
    "        # train_input에서 batch_mask에 위치하는 데이터를 불러서 batch_xs에 저장\n",
    "        batch_ys = train_label[batch_mask]\n",
    "        # batch_ys = train 데이터의 label을 저장하는 변수\n",
    "        # train_label에서 batch에 위치하는 데이터를 불러서 batch_ys에 저장\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        # feed dictionary를 선언\n",
    "        # X는 input data에 대한 placeholder이며, \n",
    "        # Y는 output data 즉, label를 담는 placeholder임\n",
    "        # X에 batch_xs를 담고, Y에 batch_ys를 담음\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        # Session을 실행\n",
    "        # cost와 optimizer를 실행한 후 c에 cost를 저장 \n",
    "        avg_cost += c / total_batch\n",
    "        # avg_cost += c/total batch : avg_cost에 (c/total_batch)를 더함\n",
    "        # 즉, cost의 평균을 avg_cost에 더하여 저장\n",
    " \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    " \n",
    "print('Learning Finished!')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.765\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "# 전체 test 데이터 중 실제로 맞춘 개수가 몇개인지 측정한 다음 \n",
    "# correct_prediction에 저장\n",
    "# tf.equal에서는 예측 값과 정답이 같으면 True 아니면 False값이 반환되는데\n",
    "# 이것을 float형으로 바꾸고 평균을 계산해 정확도를 구함\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# 정확도의 평균을 구하여 accuracy에 저장 \n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: test_input, Y: test_label}))\n",
    "# Accuracy를 출력.\n",
    "# feed_dict={X: test_input, Y: test_label} : X에 test_input을, Y에 test_input을 불러옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 방법2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data에 shuffle하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0926 10:13:10.398465  3192 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0926 10:13:10.412459  3192 deprecation.py:323] From <ipython-input-1-421f7b91e45a>:101: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.158382113\n",
      "Epoch: 0002 cost = 0.050046278\n",
      "Epoch: 0003 cost = 0.035299496\n",
      "Epoch: 0004 cost = 0.024349729\n",
      "Epoch: 0005 cost = 0.021876828\n",
      "Epoch: 0006 cost = 0.017378889\n",
      "Epoch: 0007 cost = 0.018441109\n",
      "Epoch: 0008 cost = 0.017486823\n",
      "Epoch: 0009 cost = 0.013201052\n",
      "Epoch: 0010 cost = 0.012452676\n",
      "Epoch: 0011 cost = 0.011391483\n",
      "Epoch: 0012 cost = 0.015659377\n",
      "Epoch: 0013 cost = 0.008455273\n",
      "Epoch: 0014 cost = 0.009637895\n",
      "Epoch: 0015 cost = 0.017544249\n",
      "Learning Finished!\n",
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "import tensorflow as tf\n",
    " \n",
    "TRAIN_DIR = 'D:/MNIST/trainingSet/'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    " \n",
    "train_input = []\n",
    "train_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        train_input.append([np.array(img)])\n",
    "        train_label.append([np.array(onehot_encoded[index])])\n",
    " \n",
    "train_input = np.reshape(train_input, (-1, 784))\n",
    "train_label = np.reshape(train_label, (-1, 10))\n",
    "train_input = np.array(train_input).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.float32)\n",
    "tmp = [[x,y] for x, y in zip(train_input, train_label)]\n",
    "np.random.shuffle(tmp)\n",
    "train_input = [n[0] for n in tmp]\n",
    "train_label = [n[1] for n in tmp]\n",
    "np.save(\"train_data.npy\", train_input)\n",
    "np.save(\"train_label.npy\", train_label)\n",
    " \n",
    "TEST_DIR = 'D:/MNIST/testSet/'\n",
    "test_folder_list = array(os.listdir(TEST_DIR))\n",
    " \n",
    "test_input = []\n",
    "test_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(test_folder_list)\n",
    " \n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(test_folder_list)):\n",
    "    path = os.path.join(TEST_DIR, test_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_input.append([np.array(img)])\n",
    "        test_label.append([np.array(onehot_encoded[index])])\n",
    " \n",
    "test_input = np.reshape(test_input, (-1, 784))\n",
    "test_label = np.reshape(test_label, (-1, 10))\n",
    "test_input = np.array(test_input).astype(np.float32)\n",
    "test_label = np.array(test_label).astype(np.float32)\n",
    "tmp = [[x,y] for x, y in zip(test_input, test_label)]\n",
    "np.random.shuffle(tmp)\n",
    "test_input = [n[0] for n in tmp]\n",
    "test_label = [n[1] for n in tmp]\n",
    "np.save(\"test_input.npy\",test_input)\n",
    "np.save(\"test_label.npy\",test_label)\n",
    " \n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    " \n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    " \n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    " \n",
    "# define cost/loss &amp;amp;amp; optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    " \n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    " \n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    " \n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(len(train_input) / batch_size)\n",
    " \n",
    "    for i in range(total_batch):\n",
    "        start = ((i + 1) * batch_size) - batch_size\n",
    "        end = ((i + 1) * batch_size)\n",
    "        batch_xs = train_input[start:end]\n",
    "        batch_ys = train_label[start:end]\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    " \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    " \n",
    "print('Learning Finished!')\n",
    " \n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: test_input, Y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
