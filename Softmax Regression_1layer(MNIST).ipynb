{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 이미지 데이터에 라벨링, 벡터화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_zero', '1_one', '2_two', '3_three', '4_four', '5_five', '6_six',\n",
       "       '7_seven', '8_eight', '9_nine'], dtype='<U7')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "TRAIN_DIR = 'D:/MNIST/trainingSet/'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    "train_folder_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## path 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
    "integer_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라벨링 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integer_encoded:\n",
      " [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "onehot_encoded:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print('integer_encoded:\\n', integer_encoded)\n",
    "print('onehot_encoded:\\n', onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(onehot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지를 불러와서 흑백으로 벡터화 및 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "train_input = []\n",
    "train_label = []\n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # cv2.imread: paht경로에 있는 이미지를 흑백으로 불러옴\n",
    "        train_input.append([np.array(img)])\n",
    "        train_label.append([np.array(onehot_encoded[index])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x167b7a7bd30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 마지막 이미지 시각화\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list형태를 np.array형태(42000,784)로 reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input) #train_input은 [[img],[img],...,[img]] 이런 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input.shape:  (42000, 784)\n",
      "train_label.shape:  (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_input = np.reshape(train_input, (-1, 784))\n",
    "# 이때 -1은 정확한 개수를 모를때 사용. -1대신 42000 넣어도 상관x\n",
    "train_label = np.reshape(train_label, (-1, 10))\n",
    "train_input = np.array(train_input).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.float32)\n",
    "\n",
    "#데이터 섞기\n",
    "tmp = [[x,y] for x, y in zip(train_input, train_label)]\n",
    "np.random.shuffle(tmp)\n",
    "train_input = np.array([n[0] for n in tmp])\n",
    "train_label = np.array([n[1] for n in tmp])\n",
    "\n",
    "np.save(\"train_data.npy\", train_input)\n",
    "np.save(\"train_label.npy\", train_label)\n",
    "print('train_input.shape: ', train_input.shape)\n",
    "print('train_label.shape: ', train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 이미지 데이터(200개) 숫자 변환 전체코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tldud\\.conda\\envs\\tldud\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "TEST_DIR = 'D:/MNIST/testSet/'\n",
    "test_folder_list = array(os.listdir(TEST_DIR))\n",
    " \n",
    "test_input = []\n",
    "test_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(test_folder_list)\n",
    " \n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(test_folder_list)):\n",
    "    path = os.path.join(TEST_DIR, test_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_input.append([np.array(img)])\n",
    "        test_label.append([np.array(onehot_encoded[index])])\n",
    " \n",
    "test_input = np.reshape(test_input, (-1, 784))\n",
    "test_label = np.reshape(test_label, (-1, 10))\n",
    "test_input = np.array(test_input).astype(np.float32)\n",
    "test_label = np.array(test_label).astype(np.float32)\n",
    "\n",
    "#데이터 섞기\n",
    "tmp = [[x,y] for x, y in zip(test_input, test_label)]\n",
    "np.random.shuffle(tmp)\n",
    "test_input = np.array([n[0] for n in tmp])\n",
    "test_label = np.array([n[1] for n in tmp])\n",
    "\n",
    "np.save(\"test_input.npy\",test_input)\n",
    "np.save(\"test_label.npy\",test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 소프트맥스 회귀를 이용한 MNIST 숫자 분류기 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값과 출력값을 받기 위한 플레이스홀더를 정의\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수들을 설정하고 Softmax Regression 모델을 정의\n",
    "W = tf.Variable(tf.zeros(shape=[784, 10]))\n",
    "b = tf.Variable(tf.zeros(shape=[10]))\n",
    "logits = tf.matmul(x, W) + b\n",
    "#y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-entropy 손실 함수 정의\n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred), reduction_indices=[1]))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)) \n",
    "# tf.nn.softmax_cross_entropy_with_logits API를 이용한 구현\n",
    "# reduction_indices : The old (deprecated) name for axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientDescentOptimizer 정의, Learning late는 0.5 \n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션을 열고 변수들에 초기값을 할당\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# mini-batch로 만들고 1000번의 최적화를 수행\n",
    "batch_size = 100\n",
    "for i in range(1000):\n",
    "        start = ((i+1) * batch_size) - batch_size\n",
    "        # 데이터를 분할하기 위해 start라는 변수를 선언\n",
    "        # i는 0에서 419까지 변함\n",
    "        # i = 0일 때 start에 저장되는 값은 (0+1)*100)-100이므로 0이 저장\n",
    "        end = ((i+1) * batch_size)\n",
    "        # 데이터를 분할하기 위해 end라는 변수를 선언\n",
    "        # i = 0일 때 emd에 저장되는 값은 (0+1)*100)이므로 100이 저장\n",
    "        batch_xs = train_input[start:end]\n",
    "        batch_ys = train_label[start:end]\n",
    "        feed_dict = {x: batch_xs, y: batch_ys}\n",
    "        c, _ = sess.run([loss, train_step], feed_dict=feed_dict)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "# 전체 test 데이터 중 실제로 맞춘 개수가 몇개인지 측정한 다음 correct_prediction에 저장\n",
    "# tf.argmax : 원소 중에서 가장 큰 값의 인덱스를 반환. \n",
    "# 즉, logits에서는 가중치 업데이트 후 가장 큰 값을 갖는 인덱스를 \n",
    "# y에서는 0과1 중 1인 것을 찾아서 라벨을 매기기 위함\n",
    "# tf.equal : 예측 값과 정답이 같으면 True 아니면 False값이 반환\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# tf.cast : correct_prediction을 float형으로 변환. True = 1, False = 0\n",
    "# 변환한 값의 평균을 구하여 accuracy에 저장. 200개 중 몇 개 맞췄는지\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={x: test_input, y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
